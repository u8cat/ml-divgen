import os, json, random
from typing import Iterable

import numpy as np

model_list = [
    'EleutherAI/pythia-2.8b',
    'ContextualAI/archangel_sft_pythia2-8b',
    'ContextualAI/archangel_sft-ppo_pythia2-8b',
    'ContextualAI/archangel_sft-dpo_pythia2-8b',
]

result_dir = 'model_outputs'
dataset_name = 'euclaise/writingprompts'
dataset_split = 'validation'
num_samples = 1000

# A generation is a sequence of rows, where each row is a list of sentences
# Sentences on the same row are generated by the same prompt
def distinctness(generations: Iterable[list[str]]):
    dist1, dist2, dist3 = [], [], []

    for row in generations:
        unigrams, bigrams, trigrams = set(), set(), set()
        total_words = 0
        for sentence in row:
            o = sentence.split()
            # o = [str(tok) for tok in gen]
            total_words += len(o)
            unigrams.update(o)
            for i in range(len(o) - 1):
                bigrams.add(o[i] + '_' + o[i+1])
            for i in range(len(o) - 2):
                trigrams.add(o[i] + '_' + o[i+1] + '_' + o[i+2])
        if total_words == 0:
            continue
        dist1.append(len(unigrams) / total_words)
        dist2.append(len(bigrams) / total_words)
        dist3.append(len(trigrams) / total_words)

    return np.mean(dist1), np.mean(dist2), np.mean(dist3)

if __name__ == '__main__':

    for model_name_or_path in model_list:
        result_file = f"{result_dir}/{model_name_or_path.replace('/', '_')}_{dataset_name.replace('/', '_')}_{dataset_split}_generations_{num_samples}.json"
        with open(result_file) as f:
            results: list[dict[str,str]] = json.load(f)
        assert len(results) == num_samples

    generations = list(map(lambda r: r['generated'], results))
    dist1, dist2, dist3 = distinctness(generations)

    print(f'# {model_name_or_path}')
    print(f'dist1 = {dist1:.4f}')
    print(f'dist2 = {dist2:.4f}')
    print(f'dist3 = {dist3:.4f}')
